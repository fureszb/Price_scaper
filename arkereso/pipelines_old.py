# arkereso/pipelines.py - JAV√çTOTT VERZI√ì
import json
import time
import requests
import pandas as pd
from scrapy.exceptions import DropItem
import logging
from scrapy import signals
import os

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3.1"


class GlobalData:
    """Glob√°lis adatgy≈±jt≈ë oszt√°ly"""
    items = []
    excel_written = False


def _ask_ollama(prompt: str, model: str = MODEL_NAME, retries: int = 2, timeout: int = 60) -> str:
    """Egyszer≈± h√≠v√≥ Ollam√°hoz (stream off). Visszaadja a teljes sz√∂veges v√°laszt."""
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "options": {"temperature": 0.1, "top_p": 0.9}
    }
    last_err = None
    for attempt in range(retries + 1):
        try:
            r = requests.post(OLLAMA_URL, json=payload, timeout=timeout)
            r.raise_for_status()
            data = r.json()
            return data.get("response", "").strip()
        except Exception as e:
            last_err = e
            logging.warning(f"Ollama h√≠v√°s sikertelen ({attempt + 1}/{retries + 1}): {e}")
            time.sleep(1.5)

    raise Exception(f"Ollama nem el√©rhet≈ë: {last_err}")


def _build_prompt(input_term: str, scraped_name: str, price: str, store: str) -> str:
    return f"""
Feladat: D√∂ntsd el, hogy a TAL√ÅLAT megfelel-e az INPUT term√©kre.
V√°laszolj egyetlen JSON objektummal, pontos kulcsokkal:

{{
  "relevans": "IGEN" vagy "NEM",
  "pontszam": 0..100 (eg√©sz),
  "indoklas": "r√∂vid magyar indokl√°s, max 1-2 mondat"
}}

D√∂nt√©si szempontok:
- A n√©vben egyez≈ë kulcskifejez√©sek (m√©ret, t√≠pus, menet/E27/E14, anyag, darabsz√°m).
- Ha nagyon √°ltal√°nos a tal√°lat, akkor NEM.
- Ha er≈ës egyez√©s (azonos szabv√°ny, jel√∂l√©s), akkor IGEN.

INPUT_TERM: "{input_term}"
TALALAT_NEV: "{scraped_name}"
AR: "{price} Ft"
ARUHAZ: "{store}"
""".strip()


class AIValidationPipeline:
    """Ollama 3.1 valid√°ci√≥."""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def process_item(self, item, spider):
        if not getattr(spider, 'enable_ai_validation', True):
            item["AI_Validacio"] = "KIKAPCSOLVA"
            item["AI_Pontszam"] = 0
            item["AI_Indoklas"] = "AI valid√°ci√≥ nincs enged√©lyezve"
            item["AI_Statusz"] = "AI_kikapcsolva"
            return item

        termek = item.get("termek", "")
        nev = item.get("nev", "")
        ar = item.get("ar", "")
        aruhaz = item.get("aruhaz", "")

        if not all([termek, nev, ar]):
            item["AI_Validacio"] = "HIBA"
            item["AI_Pontszam"] = 0
            item["AI_Indoklas"] = "Hi√°nyz√≥ adat"
            item["AI_Statusz"] = "AI_hiba"
            return item

        try:
            prompt = _build_prompt(termek, nev, ar, aruhaz)
            resp = _ask_ollama(prompt)

            relevans = "NEM"
            pontszam = 0
            indok = "N/A"

            try:
                start_idx = resp.find('{')
                end_idx = resp.rfind('}') + 1
                if start_idx != -1 and end_idx != 0:
                    json_str = resp[start_idx:end_idx]
                    data = json.loads(json_str)
                    relevans = str(data.get("relevans", "NEM")).strip().upper()
                    pontszam = int(data.get("pontszam", 0))
                    indok = str(data.get("indoklas", "")).strip()
            except Exception:
                self.logger.warning(f"‚ö†Ô∏è JSON parse hiba. AI v√°lasz: {resp}")
                if "IGEN" in resp.upper():
                    relevans = "IGEN"
                    pontszam = 80
                    indok = "Automatikus elfogad√°s JSON hiba miatt"
                else:
                    relevans = "NEM"
                    pontszam = 30
                    indok = "Automatikus elutas√≠t√°s JSON hiba miatt"

            item["AI_Validacio"] = relevans
            item["AI_Pontszam"] = pontszam
            item["AI_Indoklas"] = indok

            if relevans == "IGEN" and pontszam >= 60:
                item["AI_Statusz"] = "Elfogadva"
            else:
                item["AI_Statusz"] = "Elutas√≠tva_AI_alapjan"

            self.logger.info(f"ü§ñ AI: {nev} ‚Üí {relevans} ({pontszam}) - {indok}")
            return item

        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è AI valid√°ci√≥s hiba: {e}")
            item["AI_Validacio"] = "HIBA"
            item["AI_Pontszam"] = 0
            item["AI_Indoklas"] = f"Valid√°ci√≥s hiba: {str(e)}"
            item["AI_Statusz"] = "AI_hiba"
            return item


class ExcelPipeline:
    """Excel pipeline - minden spider bez√°r√°sakor √≠rja ki az adatokat"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.items = []

    @classmethod
    def from_crawler(cls, crawler):
        pipeline = cls()
        crawler.signals.connect(pipeline.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(pipeline.spider_closed, signal=signals.spider_closed)
        return pipeline

    def spider_opened(self, spider):
        self.logger.info(f"üìñ Spider elindult: {spider.name}")

    def process_item(self, item, spider):
        excel_item = {
            "aruhaz": item.get("aruhaz", ""),
            "termek": item.get("termek", ""),
            "nev": item.get("nev", ""),
            "ar": item.get("ar", ""),
            "url": item.get("url", ""),
            "AI_Validacio": item.get("AI_Validacio", "N/A"),
            "AI_Pontszam": item.get("AI_Pontszam", 0),
            "AI_Indoklas": item.get("AI_Indoklas", "N/A"),
            "AI_Statusz": item.get("AI_Statusz", "N/A"),
        }

        if excel_item["nev"] or excel_item["termek"]:
            self.items.append(excel_item)
            GlobalData.items.append(excel_item)
            self.logger.info(f"‚úÖ Term√©k hozz√°adva: {excel_item['nev'][:50]}")

        return item

    def spider_closed(self, spider):
        """Spider bez√°r√°sakor √≠rjuk ki az Excel f√°jlt"""
        self.logger.info(f"üèÅ Spider bez√°rult: {spider.name} - {len(self.items)} term√©k")

        if not GlobalData.items:
            self.logger.warning("‚ö†Ô∏è Nincs adat az Excel f√°jlhoz")
            return

        try:
            # Output f√°jl n√©v meghat√°roz√°sa
            from scrapy.utils.project import get_project_settings
            settings = get_project_settings()
            output_file = settings.get('OUTPUT_FILE', 'output_combined.xlsx')

            # Ha a f√°jl m√°r l√©tezik, olvassuk be √©s egyes√≠ts√ºk
            if os.path.exists(output_file):
                existing_df = pd.read_excel(output_file)
                new_df = pd.DataFrame(GlobalData.items)
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            else:
                combined_df = pd.DataFrame(GlobalData.items)

            # Duplik√°tumok elt√°vol√≠t√°sa
            combined_df = combined_df.drop_duplicates(subset=['aruhaz', 'nev', 'ar'], keep='first')

            # Excel f√°jl √≠r√°sa
            combined_df.to_excel(output_file, index=False)

            self.logger.info(f"üéâ {len(combined_df)} term√©k mentve: {output_file}")

            # Statisztika
            by_store = combined_df.groupby('aruhaz').size()
            by_product = combined_df.groupby('termek').size()

            self.logger.info("üìä Statisztika:")
            self.logger.info(f"   √Åruh√°zak: {dict(by_store)}")
            self.logger.info(f"   Term√©kek: {dict(by_product)}")

        except Exception as e:
            self.logger.error(f"‚ùå Excel √≠r√°si hiba: {e}")
            import traceback
            traceback.print_exc()