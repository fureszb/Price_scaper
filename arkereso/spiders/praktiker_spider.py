import scrapy
from scrapy_playwright.page import PageMethod

class PraktikerSpider(scrapy.Spider):
    name = "praktiker"

    def __init__(self, termek="", enable_ai_validation=True, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.termek = termek
        self.enable_ai_validation = enable_ai_validation

    def start_requests(self):
        url = f"https://www.praktiker.hu/search/{self.termek}"
        yield scrapy.Request(
            url,
            meta={
                "playwright": True,
                "playwright_page_methods": [
                    # ‚úÖ Cookie popup elfogad√°sa
                    PageMethod("wait_for_selector", "body", timeout=10000),
                    PageMethod(
                        "evaluate",
                        """
                        () => {
                            const selectors = [
                                '#onetrust-accept-btn-handler',
                                'button:has-text("Elfogadom")',
                                'button.cookie-accept',
                                '[data-accept*="cookie"]'
                            ];
                            for (const sel of selectors) {
                                const btn = document.querySelector(sel);
                                if (btn) { btn.click(); }
                            }
                        }
                        """
                    ),
                    # ‚úÖ Stabil szelektor a val√≥di term√©kk√°rty√°kra
                    PageMethod("wait_for_selector", ".prefixbox-product-container .prefixbox-product", timeout=30000)
                ],
            },
            callback=self.parse,
            errback=self.handle_error
        )

    def parse(self, response):
        # ‚úÖ Csak a val√≥s term√©kk√°rty√°kat vessz√ºk (nem a placeholder-eket)
        products = response.css(".prefixbox-product-container .prefixbox-product")[:5]

        if not products:
            self.logger.warning(f"‚ùå Nincs tal√°lat a Praktiker oldalon: {self.termek}")

        for product in products:
            # ‚úÖ Term√©kn√©v
            nev = product.css(".prefixbox-product-name::text").get()
            if not nev:
                nev = product.css(".prefixbox-product-name span::text").get()

            # ‚úÖ √År lek√©r√©se biztons√°gosan
            ar = product.css("#price-with-currency .line-clamp-1::text").get()
            if not ar:
                ar = product.xpath(".//div[@id='price-with-currency']//text()").get()

            # ‚úÖ Link lek√©r√©se
            url = product.css("a.pfbx-product-link::attr(href)").get()

            if nev and ar:
                # üîß √År tiszt√≠t√°sa
                ar = (
                    ar.replace("\xa0", "")
                    .replace("Ft", "")
                    .replace("/", "")
                    .replace("darab", "")
                    .replace(" ", "")
                    .strip()
                )

                # üîó URL kieg√©sz√≠t√©se
                if url and not url.startswith("http"):
                    url = "https://www.praktiker.hu" + url

                yield {
                    "aruhaz": "Praktiker",
                    "termek": self.termek,
                    "nev": nev.strip(),
                    "ar": ar,
                    "url": url or response.url,
                }
            else:
                self.logger.warning(f"‚ö†Ô∏è Hi√°nyz√≥ adat term√©k eset√©n: nev={nev}, ar={ar}, url={url}")

    def handle_error(self, failure):
        self.logger.error(f"‚ö†Ô∏è Hiba a Praktiker lek√©r√©s k√∂zben: {failure.value}")
