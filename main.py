# main.py - JAV√çTOTT VERZI√ì
import argparse
import pandas as pd
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
import datetime
import os
import sys

# Biztos√≠tsuk, hogy a projekt root el√©rhet≈ë
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)


def main():
    # === Parancssori argumentumok kezel√©se ===
    parser = argparse.ArgumentParser(description="√Årkeres≈ë futtat√≥")
    parser.add_argument("--debug", type=int, default=0, help="1 = l√°that√≥ b√∂ng√©sz≈ë, 0 = headless")
    args = parser.parse_args()

    # Excel input ellen≈ërz√©s
    input_file = "input.xlsx"
    if not os.path.exists(input_file):
        print(f"‚ùå Nem tal√°lhat√≥ input f√°jl: {input_file}")
        return

    df = pd.read_excel(input_file)
    if "termek" not in df.columns:
        print("‚ùå Az input.xlsx f√°jl nem tartalmaz 'termek' oszlopot.")
        return

    termek_lista = df["termek"].dropna().tolist()
    if not termek_lista:
        print("‚ùå Nincs feldolgozhat√≥ term√©k az input.xlsx f√°jlban.")
        return

    # Projekt settings bet√∂lt√©se vagy alap√©rtelmezett be√°ll√≠t√°sok
    try:
        settings = get_project_settings()
    except:
        print("‚ö†Ô∏è Nem tal√°lhat√≥ settings f√°jl, alap√©rtelmezett be√°ll√≠t√°sok haszn√°lata")
        settings = {
            'BOT_NAME': 'arkereso',
            'SPIDER_MODULES': ['arkereso.spiders'],
            'NEWSPIDER_MODULE': 'arkereso.spiders',
            'ROBOTSTXT_OBEY': False,
            'PLAYWRIGHT_LAUNCH_OPTIONS': {
                "headless": not bool(args.debug),
            },
            'ITEM_PIPELINES': {
                'arkereso.pipelines.AIValidationPipeline': 300,
                'arkereso.pipelines.ExcelPipeline': 800,
            },
            'DOWNLOADER_MIDDLEWARES': {
                'scrapy_playwright.middleware.PlaywrightMiddleware': 800,
            },
            'CONCURRENT_REQUESTS': 1,
            'DOWNLOAD_DELAY': 1,
        }

    # Playwright be√°ll√≠t√°sok
    debug_mode = bool(args.debug)
    settings.set("PLAYWRIGHT_LAUNCH_OPTIONS", {
        "headless": not debug_mode,
        "slow_mo": 500 if debug_mode else 0
    })

    print(f"üîß Debug m√≥d: {'L√ÅTHAT√ì' if debug_mode else 'HEADLESS'}")
    print(f"üîç Keresett term√©kek: {', '.join(termek_lista)}")

    # Timestamp
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    print(f"üïí Futtat√°s id≈ëpontja: {timestamp}")

    # Scrapy process
    process = CrawlerProcess(settings)

    # Spider-ek import√°l√°sa
    try:
        from arkereso.spiders.bauhause_spider import BauhausSpider
        from arkereso.spiders.obi_spider import ObiSpider
        from arkereso.spiders.praktiker_spider import PraktikerSpider

        # √ñsszes term√©k lek√©rdez√©s futtat√°sa minden spiderrel
        for termek in termek_lista:
            print(f"üöÄ Keres√©s ind√≠t√°sa: {termek}")
            process.crawl(BauhausSpider, termek=termek)
            process.crawl(ObiSpider, termek=termek)
            process.crawl(PraktikerSpider, termek=termek)

        # Folyamat ind√≠t√°sa
        print("üé¨ Scrapy folyamat ind√≠t√°sa...")
        process.start()
        print("‚úÖ Scrapy folyamat befejez≈ëd√∂tt!")

    except Exception as e:
        print(f"‚ùå Hiba a spider-ek ind√≠t√°sakor: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()